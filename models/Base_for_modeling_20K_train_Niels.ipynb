{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QKhi32tiwfkZ",
        "outputId": "dc4ef666-0a25-460e-e61f-ae5975fb34d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub) (4.66.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub) (2024.8.30)\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/vipoooool/new-plant-diseases-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.70G/2.70G [00:40<00:00, 70.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/vipoooool/new-plant-diseases-dataset/versions/2\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub\n",
        "from google.colab import files\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download the latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"vipoooool/new-plant-diseases-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the dataset path\n",
        "root_folder = \"/root/.cache/kagglehub/datasets/vipoooool/new-plant-diseases-dataset/versions/2\"\n",
        "\n",
        "data_dir = os.path.join(root_folder, 'new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)/')\n",
        "\n",
        "test_path = os.path.join(root_folder, 'test/test')\n",
        "train_path = os.path.join(data_dir, 'train')\n",
        "valid_path = os.path.join(data_dir, 'valid')\n",
        "\n",
        "# Count the number of folders in a directory\n",
        "def count_folders(path):\n",
        "    if os.path.exists(path):\n",
        "        return len([d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))])\n",
        "    else:\n",
        "        print(f\"Path does not exist: {path}\")\n",
        "        return 0\n",
        "\n",
        "# Count the number of files in a directory\n",
        "def count_files(path):\n",
        "    if os.path.exists(path):\n",
        "        return len([f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))])\n",
        "    else:\n",
        "        print(f\"Path does not exist: {path}\")\n",
        "        return 0\n",
        "\n",
        "# Function to count files in each folder of a given directory\n",
        "def count_files_in_folders(path):\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"Path does not exist: {path}\")\n",
        "        return {}\n",
        "\n",
        "    folder_file_counts = {}\n",
        "    for folder in os.listdir(path):\n",
        "        folder_path = os.path.join(path, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            file_count = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "            folder_file_counts[folder] = file_count\n",
        "\n",
        "    return folder_file_counts\n",
        "\n",
        "# Print counts\n",
        "print(f\"Number of folders in train_path: {count_folders(train_path)}\")\n",
        "print(f\"Number of folders in valid_path: {count_folders(valid_path)}\")\n",
        "print(f\"Number of files in test_path: {count_files(test_path)}\")\n",
        "print('-------------------------------------------------------------------')\n",
        "# Count files in each folder\n",
        "train_folder_counts = count_files_in_folders(train_path)\n",
        "valid_folder_counts = count_files_in_folders(valid_path)\n",
        "# Display results\n",
        "print(\"Files in each folder (train_path):\")\n",
        "for folder, count in train_folder_counts.items():\n",
        "    print(f\"{folder}: {count} files\")\n",
        "\n",
        "print(\"\\nFiles in each folder (valid_path):\")\n",
        "for folder, count in valid_folder_counts.items():\n",
        "    print(f\"{folder}: {count} files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "da9uyFyiwis-",
        "outputId": "02bba575-b795-4e01-cda8-b9c5c607e433"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of folders in train_path: 38\n",
            "Number of folders in valid_path: 38\n",
            "Number of files in test_path: 33\n",
            "-------------------------------------------------------------------\n",
            "Files in each folder (train_path):\n",
            "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 1642 files\n",
            "Pepper,_bell___healthy: 1988 files\n",
            "Tomato___Late_blight: 1851 files\n",
            "Tomato___Tomato_mosaic_virus: 1790 files\n",
            "Soybean___healthy: 2022 files\n",
            "Squash___Powdery_mildew: 1736 files\n",
            "Tomato___Leaf_Mold: 1882 files\n",
            "Tomato___Target_Spot: 1827 files\n",
            "Potato___Late_blight: 1939 files\n",
            "Grape___healthy: 1692 files\n",
            "Potato___healthy: 1824 files\n",
            "Tomato___healthy: 1926 files\n",
            "Raspberry___healthy: 1781 files\n",
            "Peach___Bacterial_spot: 1838 files\n",
            "Apple___Cedar_apple_rust: 1760 files\n",
            "Corn_(maize)___Common_rust_: 1907 files\n",
            "Orange___Haunglongbing_(Citrus_greening): 2010 files\n",
            "Tomato___Bacterial_spot: 1702 files\n",
            "Blueberry___healthy: 1816 files\n",
            "Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 1722 files\n",
            "Corn_(maize)___Northern_Leaf_Blight: 1908 files\n",
            "Grape___Black_rot: 1888 files\n",
            "Apple___Black_rot: 1987 files\n",
            "Tomato___Septoria_leaf_spot: 1745 files\n",
            "Tomato___Early_blight: 1920 files\n",
            "Tomato___Tomato_Yellow_Leaf_Curl_Virus: 1961 files\n",
            "Apple___Apple_scab: 2016 files\n",
            "Tomato___Spider_mites Two-spotted_spider_mite: 1741 files\n",
            "Pepper,_bell___Bacterial_spot: 1913 files\n",
            "Corn_(maize)___healthy: 1859 files\n",
            "Cherry_(including_sour)___Powdery_mildew: 1683 files\n",
            "Cherry_(including_sour)___healthy: 1826 files\n",
            "Grape___Esca_(Black_Measles): 1920 files\n",
            "Potato___Early_blight: 1939 files\n",
            "Strawberry___healthy: 1824 files\n",
            "Apple___healthy: 2008 files\n",
            "Strawberry___Leaf_scorch: 1774 files\n",
            "Peach___healthy: 1728 files\n",
            "\n",
            "Files in each folder (valid_path):\n",
            "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 410 files\n",
            "Pepper,_bell___healthy: 497 files\n",
            "Tomato___Late_blight: 463 files\n",
            "Tomato___Tomato_mosaic_virus: 448 files\n",
            "Soybean___healthy: 505 files\n",
            "Squash___Powdery_mildew: 434 files\n",
            "Tomato___Leaf_Mold: 470 files\n",
            "Tomato___Target_Spot: 457 files\n",
            "Potato___Late_blight: 485 files\n",
            "Grape___healthy: 423 files\n",
            "Potato___healthy: 456 files\n",
            "Tomato___healthy: 481 files\n",
            "Raspberry___healthy: 445 files\n",
            "Peach___Bacterial_spot: 459 files\n",
            "Apple___Cedar_apple_rust: 440 files\n",
            "Corn_(maize)___Common_rust_: 477 files\n",
            "Orange___Haunglongbing_(Citrus_greening): 503 files\n",
            "Tomato___Bacterial_spot: 425 files\n",
            "Blueberry___healthy: 454 files\n",
            "Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 430 files\n",
            "Corn_(maize)___Northern_Leaf_Blight: 477 files\n",
            "Grape___Black_rot: 472 files\n",
            "Apple___Black_rot: 497 files\n",
            "Tomato___Septoria_leaf_spot: 436 files\n",
            "Tomato___Early_blight: 480 files\n",
            "Tomato___Tomato_Yellow_Leaf_Curl_Virus: 490 files\n",
            "Apple___Apple_scab: 504 files\n",
            "Tomato___Spider_mites Two-spotted_spider_mite: 435 files\n",
            "Pepper,_bell___Bacterial_spot: 478 files\n",
            "Corn_(maize)___healthy: 465 files\n",
            "Cherry_(including_sour)___Powdery_mildew: 421 files\n",
            "Cherry_(including_sour)___healthy: 456 files\n",
            "Grape___Esca_(Black_Measles): 480 files\n",
            "Potato___Early_blight: 485 files\n",
            "Strawberry___healthy: 456 files\n",
            "Apple___healthy: 502 files\n",
            "Strawberry___Leaf_scorch: 444 files\n",
            "Peach___healthy: 432 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "SRb5EYrgwpWN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists\n",
        "image_paths = []\n",
        "species_labels = []\n",
        "disease_labels = []\n",
        "dataset_split = []\n",
        "\n",
        "# Function to process a dataset directory\n",
        "def process_directory(base_path, split_name):\n",
        "    for class_folder in os.listdir(base_path):\n",
        "        class_folder_path = os.path.join(base_path, class_folder)\n",
        "        if os.path.isdir(class_folder_path):\n",
        "            species, disease = class_folder.split('___')\n",
        "            for image_name in os.listdir(class_folder_path):\n",
        "                image_paths.append(os.path.join(class_folder_path, image_name))\n",
        "                species_labels.append(species)\n",
        "                disease_labels.append(disease)\n",
        "                dataset_split.append(split_name)\n",
        "\n",
        "# Process train and valid\n",
        "process_directory(train_path, 'train')\n",
        "process_directory(valid_path, 'valid')\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'image_path': image_paths,\n",
        "    'species': species_labels,\n",
        "    'disease': disease_labels,\n",
        "    'split': dataset_split\n",
        "})\n",
        "\n",
        "# Display first few rows\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tKZ2tbl0w2uM",
        "outputId": "b55e424d-b0c4-47f3-d519-b37f16353b4c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          image_path       species  \\\n",
            "0  /root/.cache/kagglehub/datasets/vipoooool/new-...  Corn_(maize)   \n",
            "1  /root/.cache/kagglehub/datasets/vipoooool/new-...  Corn_(maize)   \n",
            "2  /root/.cache/kagglehub/datasets/vipoooool/new-...  Corn_(maize)   \n",
            "3  /root/.cache/kagglehub/datasets/vipoooool/new-...  Corn_(maize)   \n",
            "4  /root/.cache/kagglehub/datasets/vipoooool/new-...  Corn_(maize)   \n",
            "\n",
            "                               disease  split  \n",
            "0  Cercospora_leaf_spot Gray_leaf_spot  train  \n",
            "1  Cercospora_leaf_spot Gray_leaf_spot  train  \n",
            "2  Cercospora_leaf_spot Gray_leaf_spot  train  \n",
            "3  Cercospora_leaf_spot Gray_leaf_spot  train  \n",
            "4  Cercospora_leaf_spot Gray_leaf_spot  train  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduced training data to 20K"
      ],
      "metadata": {
        "id": "lBnJCxml2R-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df[df['split'] == 'train']\n",
        "\n",
        "# Calculate the desired proportion for each class\n",
        "class_proportions = train_df['species'].value_counts(normalize=True)\n",
        "\n",
        "# Calculate the number of images per class for the reduced dataset\n",
        "class_counts = (class_proportions * 20000).astype(int)\n",
        "\n",
        "# Create a new directory for the reduced dataset\n",
        "reduced_train_path = '/content/reduced_train'  # Or any desired path\n",
        "os.makedirs(reduced_train_path, exist_ok=True)\n",
        "\n",
        "# Copy images to the new directory, maintaining proportions\n",
        "for species, count in class_counts.items():\n",
        "    # Filter DataFrame for the current species\n",
        "    species_df = train_df[train_df['species'] == species]\n",
        "\n",
        "    # Randomly select 'count' images from the species\n",
        "    selected_images = species_df.sample(count, random_state=42)  # Set random_state for reproducibility\n",
        "\n",
        "    # Create a subdirectory for the species in the reduced dataset\n",
        "    species_dir = os.path.join(reduced_train_path, species)\n",
        "    os.makedirs(species_dir, exist_ok=True)\n",
        "\n",
        "    # Copy the selected images to the new subdirectory\n",
        "    for _, row in selected_images.iterrows():\n",
        "        shutil.copy(row['image_path'], species_dir)\n",
        "\n",
        "print(f\"Reduced training dataset created at: {reduced_train_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlifjyiUxNSv",
        "outputId": "09e86763-0d85-4979-de22-71a2c165d9ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced training dataset created at: /content/reduced_train\n"
          ]
        }
      ]
    }
  ]
}